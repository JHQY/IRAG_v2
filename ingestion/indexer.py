# ingestion/indexer.py
from ingestion.loader import scan_documents
from ingestion.parser import parse_pdf
from ingestion.chunker import chunk_blocks
from embedding.embedder import Embedder
from storage.milvus_store import MilvusVectorStore
from config.settings import settings
from tqdm import tqdm

# def build_index(source_dir="sourcepdf"):
#     """
#     æ„å»ºä¿é™©çŸ¥è¯†åº“ç´¢å¼•ï¼š
#     1. æ‰«ææ‰€æœ‰æ–‡ä»¶
#     2. æŠ½å–æ–‡å­— + è¡¨æ ¼ï¼ˆå¸¦ä¸Šä¸‹æ–‡ï¼‰
#     3. å¯¹æ–‡å­—å†…å®¹åˆ†å—
#     4. åµŒå…¥ + å†™å…¥ Milvus
#     """
#     print("ğŸš€ å¼€å§‹æ„å»ºç´¢å¼• ...")
#     docs = scan_documents(source_dir)
#     if not docs:
#         print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¯ç´¢å¼•çš„æ–‡ä»¶ã€‚")
#         return

#     embedder = Embedder()
#     store = MilvusVectorStore()
#     total_chunks = 0

#     for doc in tqdm(docs, desc="ç´¢å¼•è¿›åº¦"):
#         try:
#             parsed_blocks = parse_pdf(doc["path"])
#             # print(f"ğŸ“„ è§£æå®Œæˆï¼š{doc['path']}ï¼Œæå–åˆ° {len(parsed_blocks)} ä¸ªå†…å®¹å—ã€‚")
#             # print(f"é¢„è§ˆå†…å®¹å—ï¼š{parsed_blocks[:2]}")  # æ‰“å°å‰ä¸¤ä¸ªå†…å®¹å—ä»¥ä¾›è°ƒè¯•
#             if not parsed_blocks:
#                 print(f"âš ï¸ æ–‡ä»¶æ— æœ‰æ•ˆå†…å®¹ï¼š{doc['path']}")
#                 continue

#             for block in parsed_blocks:
#                 # content = block.get("text", "").strip()
#                 # modality = block.get("modality", "text")
#                 # page = block.get("page", 0)
                

#                 # è·³è¿‡ç©ºå—
#                 if not content:
#                     continue

#                 # ä»…æ–‡æœ¬è¿›è¡Œåˆ†å—ï¼›è¡¨æ ¼ä¿æŒæ•´å—
#                 if modality == "text":
#                     chunks = chunk_blocks(parsed_blocks)
#                 else:
#                     chunks = [content]
                
#                 for c in chunks:
#                     emb = embedder.embed_text([c])[0]
#                     meta = {
#                         **doc["metadata"],
#                         "page": page,
#                         "modality": modality
#                     }
#                     store.add([emb], [Chunk(c, meta)])
#                     total_chunks += 1

#         except Exception as e:
#             print(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {doc['path']} ({e})")

#     print(f"âœ… ç´¢å¼•å®Œæˆï¼Œå…±å†™å…¥ {total_chunks} ä¸ªæ–‡æœ¬å—ã€‚")
import numpy as np
import zlib
import json
import base64

def ensure_1d(vec, dim=None):
    if vec is None:
        return None

    # numpy: squeeze to 1D
    if isinstance(vec, np.ndarray):
        vec = vec.reshape(-1,).astype("float32")
        return vec

    # list: flatten ALL nested lists robustly
    if isinstance(vec, list):
        flattened = []

        def _flatten(x):
            if isinstance(x, list):
                for e in x:
                    _flatten(e)
            else:
                flattened.append(float(e))

        _flatten(vec)  # recursive flatten

        vec = np.array(flattened, dtype="float32")

    # fix dimension if provided
    if dim is not None and len(vec) != dim:
        if len(vec) > dim:
            vec = vec[:dim]
        else:
            vec = np.pad(vec, (0, dim - len(vec)))

    return vec



def compress_table_json(table_json: dict) -> str:
    if not table_json:
        return ""
    raw = json.dumps(table_json).encode("utf-8")
    zipped = zlib.compress(raw)
    return base64.b64encode(zipped).decode("utf-8")


def build_index(source_dir="sourcepdf"):

    print("ğŸš€ å¼€å§‹æ„å»º IRAG_MM å¤šæ¨¡æ€ç´¢å¼• ...")

    docs = scan_documents(source_dir)
    if not docs:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¯ç´¢å¼•çš„æ–‡ä»¶ã€‚")
        return

    embedder = Embedder()
    store = MilvusVectorStore()

    total = 0
    batch_records = []
    batch_size = 100


    for doc in tqdm(docs, desc="ç´¢å¼•è¿›åº¦"):
        try:
            blocks = parse_pdf(doc["path"])
            if not blocks:
                print(f"âš ï¸ æ— æœ‰æ•ˆå†…å®¹ï¼š{doc['path']}")
                continue

            # æ³¨å…¥ metadata
            for b in blocks:
                b.setdefault("metadata", {})
                b["metadata"].update({
                    "source": doc.get("path", ""),
                    "company": doc.get("company", ""),
                    "category": doc.get("category", ""),
                    "page_number": b["metadata"].get("page_number"),
                    "modality": b.get("modality"),
                })

            # chunk åŒ–æ–‡æœ¬/è¡¨æ ¼
            chunks = chunk_blocks(blocks, max_length=500, overlap=50)

            # ------------------------------------------------------
            # ä¸ºæ¯ä¸ª chunk æ„é€  record
            # ------------------------------------------------------
            for c in chunks:
                modality = c.get("modality")
                meta = c.get("metadata", {})

                text_value = None
                #table_json = None
                table_blob = None
                text_vec = None
                table_vec = None

                # æ–‡æœ¬å—
                if modality == "text":
                    raw_text = (c.get("text") or "").strip()
                    if not raw_text:
                        continue

                    text_value = raw_text
                    # embed_text è¿”å› shape: (1,1024)
                    text_vec = embedder.embed_text([raw_text])[0]

                # è¡¨æ ¼å—
                elif modality == "table":
                    table = c.get("table")
                    if not table:
                        continue

                    header = table.get("header", [])
                    rows = table.get("rows", [])

                    table_json = table
                    table_blob = compress_table_json(table_json)
                    table_vec = embedder.embed_table(header, rows)

                else:
                    continue

                # è‡³å°‘è¦æœ‰ä¸€ä¸ª vector
                if text_vec is None and table_vec is None:
                    continue

                # ----------- å…³é”®ï¼šflatten vector -----------------
                if text_vec is not None:
                    print("DEBUG TEXT_VEC:", text_vec, type(text_vec))
                    text_vec = ensure_1d(text_vec, store.text_dim)

                if table_vec is not None:
                    table_vec = ensure_1d(table_vec, store.table_dim)

                batch_records.append({
                    "modality": modality,
                    "text": text_value,
                    #"table_json": table_json,
                    "table_blob": table_blob,
                    "text_vec": text_vec,
                    "table_vec": table_vec,
                    "metadata": meta,
                })


                # æ‰¹é‡å†™å…¥
                if len(batch_records) >= batch_size:
                    store.add_records(batch_records)
                    total += len(batch_records)
                    batch_records = []

        except Exception as e:
            print(f"âŒ æ–‡ä»¶å¤±è´¥ï¼š{doc['path']} ({e})")

    # å‰©ä½™å†™å…¥
    if batch_records:
        store.add_records(batch_records)
        total += len(batch_records)

    print(f"ğŸ‰ å¤šæ¨¡æ€ç´¢å¼•æ„å»ºå®Œæˆï¼Œå…±å†™å…¥ {total} ä¸ªå—ã€‚")
