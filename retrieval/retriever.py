# '''Retriever placeholder'''
# """
# RAG æŸ¥è¯¢æ¥å£æ¨¡å—
# ä¸ºé—®ç­”åŒå­¦æä¾›ï¼šç®€å•è°ƒç”¨å³å¯ä½¿ç”¨å‘é‡çŸ¥è¯†æ£€ç´¢ã€‚
# """

# from embedding.embedder import Embedder
# from storage.milvus_store import MilvusVectorStore
# import numpy as np


# class RAGInterface:
#     """é¢å‘é—®ç­”æ¨¡å—çš„ RAG æ¥å£å°è£…"""

#     def __init__(self):
#         print("ğŸ”— åˆå§‹åŒ– RAG æ¥å£ç»„ä»¶...")
#         self.embedder = Embedder()
#         self.store = MilvusVectorStore()

#     # ------------------------------------------------------
#     # åŸºç¡€æœç´¢æ¥å£
#     # ------------------------------------------------------
#     def retrieve(self, query: str, top_k: int = 5, filters: dict = None):
#         """
#         è¾“å…¥æŸ¥è¯¢è¯­å¥ -> è¾“å‡ºæœ€ç›¸ä¼¼æ–‡æœ¬å—åŠå…ƒä¿¡æ¯ã€‚
#         å‚æ•°ï¼š
#           query: str â€”â€” é—®é¢˜æ–‡æœ¬
#           top_k: int â€”â€” è¿”å›å‰å¤šå°‘æ¡ç›¸ä¼¼å†…å®¹
#           filters: dict â€”â€” å¯é€‰è¿‡æ»¤æ¡ä»¶ï¼Œå¦‚ {"company": "AIA"}
#         è¿”å›ï¼š
#           List[{"text": str, "score": float, "metadata": dict}]
#         """
#         # 1ï¸âƒ£ åµŒå…¥ query
#         try:
#             q_emb = self.embedder.embed_query(query)
#         except Exception as e:
#             print(f"âŒ æŸ¥è¯¢åµŒå…¥å¤±è´¥: {e}")  
#             raw_emb = self.embedder.model.encode([query], convert_to_numpy=True, show_progress_bar=False)   
#             q_emb = np.array(raw_emb, dtype=np.float32)[0]
        
#         if isinstance(q_emb, np.ndarray) and q_emb.ndim >1:
#             q_emb = q_emb[0]
       
#         # 2ï¸âƒ£ ç›¸ä¼¼æ£€ç´¢
#         hits = self.store.similarity_search(q_emb, top_k=top_k, filters=filters)

#         # 3ï¸âƒ£ ç»“æ„åŒ–è¾“å‡º
#         results = []
#         for chunk, score in hits:
#             results.append({
#                 "text": chunk.text,
#                 "score": round(score, 4),
#                 "metadata": chunk.metadata
#             })

#         return results

#     # ------------------------------------------------------
#     # é«˜çº§æ¥å£ï¼ˆé¢„ç•™ç»™ LLM ä½¿ç”¨ï¼‰
#     # ------------------------------------------------------
#     def retrieve_context(self, query: str, top_k: int = 5):
#         """
#         è¿”å›ä¸€ä¸ªåˆå¹¶åçš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ï¼Œå¯ç›´æ¥é€å…¥ LLMã€‚
#         """
#         hits = self.retrieve(query, top_k=top_k)
#         context = "\n---\n".join([f"{h['text']}" for h in hits])
#         return context


# # -------------------------
# # è°ƒè¯•å…¥å£ï¼ˆå¯ç‹¬ç«‹è¿è¡Œï¼‰
# # -------------------------
# if __name__ == "__main__":
#     rag = RAGInterface()
#     query = "æ€•å‡ºæ„å¤–åº”è¯¥ä¹°å“ªä¸ªä¿é™©ï¼Ÿ"
#     results = rag.retrieve(query, top_k=3)
#     print("\nğŸ” Top-3 ç»“æœ:")
#     for i, r in enumerate(results, 1):
#         print(f"\n{i}. [score={r['score']}]")
#         print(r["text"][:400], "...")
#         print("metadata:", r["metadata"])

"""
å¤šæ¨¡æ€ï¼ˆæ–‡æœ¬ + è¡¨æ ¼ï¼‰RAG æ¥å£
- æ–‡æœ¬æ£€ç´¢ï¼štext_vector (bge-m3)
- è¡¨æ ¼æ£€ç´¢ï¼štable_vector (TAPAS + è¡¨æ ¼å¢å¼ºæ–‡æœ¬)
- RAG-Fusionï¼šåŸºäº reciprocal rank çš„åŠ æƒèåˆ
- Cross-Encoder Re-rankingï¼šBAAI/bge-reranker-base

å¤–éƒ¨è°ƒç”¨ä¿æŒä¸å˜ï¼š
    rag = RAGInterface()
    rag.retrieve("æ¢åœ°æ¿å¯ä»¥èµ”å¤šå°‘ï¼Ÿ")
    rag.retrieve_context("æ¢åœ°æ¿å¯ä»¥èµ”å¤šå°‘ï¼Ÿ")
"""

"""
å¤šæ¨¡æ€ï¼ˆæ–‡æœ¬ + è¡¨æ ¼ï¼‰RAG æ¥å£
- æ–‡æœ¬æ£€ç´¢ï¼štext_vector (bge-m3)
- è¡¨æ ¼æ£€ç´¢ï¼štable_vector (TAPAS)
- RAG-Fusionï¼šåŸºäº reciprocal rank çš„åŠ æƒèåˆ
- Cross-Encoder Re-rankingï¼šBAAI/bge-reranker-base
"""

from embedding.embedder import Embedder
from storage.milvus_store import MilvusVectorStore
from retrieval.reranker import Reranker
import zlib
import json
import base64

class RAGInterface:
    def __init__(
        self,
        w_text: float = 1.0,     # æ–‡æœ¬æ£€ç´¢æƒé‡
        w_table: float = 1.0,    # è¡¨æ ¼æ£€ç´¢æƒé‡
        gamma: float = 0.7,      # reranker åœ¨æœ€ç»ˆèåˆä¸­çš„æƒé‡
        candidate_multiplier: int = 3,   # å…ˆå–å¤šå°‘å€™é€‰å†ç²¾æ’
    ):
        print("ğŸ”— åˆå§‹åŒ–å¤šæ¨¡æ€ RAG æ¥å£ç»„ä»¶...")
        self.embedder = Embedder()
        self.store = MilvusVectorStore()
        self.reranker = Reranker()

        self.w_text = w_text
        self.w_table = w_table
        self.gamma = gamma
        self.candidate_multiplier = candidate_multiplier
    



    # ------------------------------------------------------
    # æ ¸å¿ƒæ¥å£
    # ------------------------------------------------------
    def retrieve(self, query: str, top_k: int = 5, filters: dict = None):

        def decompress_table_blob(blob: str) -> dict:
            if not blob:
                return {}
            data = base64.b64decode(blob)
            raw = zlib.decompress(data)
            return json.loads(raw.decode("utf-8"))

        if not query or not isinstance(query, str):
            return []

        # 1ï¸âƒ£ Query â†’ æ–‡æœ¬ embedding
        try:
            q_vec_text = self.embedder.embed_text([query])[0]
        except Exception as e:
            print(f"âŒ æ–‡æœ¬ embedding å¤±è´¥: {e}")
            return []

        # 2ï¸âƒ£ Query â†’ è¡¨æ ¼ embeddingï¼ˆå…³é”®æ­¥éª¤ï¼‰
        try:
            q_vec_table = self.embedder.embed_query_table(query)
        except Exception as e:
            print(f"âš ï¸ è¡¨æ ¼ embedding å¤±è´¥ï¼Œfallback æ–‡æœ¬æ¨¡å¼: {e}")
            q_vec_table = q_vec_text

        # ---------------------------
        # å¤šè·¯æ£€ç´¢
        # ---------------------------
        k_each = max(top_k * self.candidate_multiplier, top_k)

        # æ–‡æœ¬é€šé“
        text_hits = self.store.search_text(q_vec_text, top_k=k_each)

        # è¡¨æ ¼é€šé“ï¼ˆç°åœ¨ä½¿ç”¨ TAPAS embeddingï¼‰
        table_hits = self.store.search_table(q_vec_table, top_k=k_each)

        if not text_hits and not table_hits:
            return []

        # ------------------------------------------------------
        # 3ï¸âƒ£ RAG-Fusion
        # ------------------------------------------------------
        fusion_map = {}

        def make_doc_id(ent):
            meta = ent.get("metadata") or {}
            source = meta.get("source", "unknown")
            page = meta.get("page_number", "na")

            # ä¸¤æ¨¡æ€ç‰ˆæœ¬ï¼šä»¥ PDF + é¡µç  ä¸ºå”¯ä¸€ ID
            # â†’ èƒ½æŠŠ table-hit å’Œ åŒé¡µçš„ text-hit è‡ªåŠ¨èåˆ
            return f"{source}|p{page}"

        def _add_hits(hits, modality_label, weight):
            for rank, hit in enumerate(hits, start=1):

                ent = hit.entity
                doc_id = make_doc_id(ent)

                if doc_id not in fusion_map:
                    fusion_map[doc_id] = {
                        "fusion_score": 0.0,
                        "item": {
                            "modality": modality_label,
                            "text": ent.get("text"),
                            "table": decompress_table_blob(ent.get("table_blob")),
                            "metadata": ent.get("metadata"),
                        }
                    }

                fusion_map[doc_id]["fusion_score"] += weight * (1.0 / rank)

        # ---- å¤šæ¨¡æ€åŠ å…¥ fusion ----
        _add_hits(text_hits, "text", self.w_text)
        _add_hits(table_hits, "table", self.w_table)

        _add_hits(text_hits,  "text",  self.w_text)
        _add_hits(table_hits, "table", self.w_table)

        if not fusion_map:
            return []

        # ------------------------------------------------------
        # 4ï¸âƒ£ topN å€™é€‰ï¼ˆå…ˆæŒ‰ fusion_score æ’åºï¼‰
        # ------------------------------------------------------
        fused_items = list(fusion_map.values())
        fused_items.sort(key=lambda x: x["fusion_score"], reverse=True)

        candidate_count = min(len(fused_items), max(top_k * self.candidate_multiplier, top_k))
        fused_items = fused_items[:candidate_count]

        candidate_texts = [fi["item"]["text"] or "" for fi in fused_items]

        # ------------------------------------------------------
        # 5ï¸âƒ£ reranker ç²¾æ’
        # ------------------------------------------------------
        rerank_scores = self.reranker.rerank(query, candidate_texts)

        fusion_scores = [fi["fusion_score"] for fi in fused_items]
        f_max, f_min = max(fusion_scores), min(fusion_scores)
        r_max, r_min = max(rerank_scores), min(rerank_scores)

        def _norm(x, lo, hi):
            if hi <= lo:
                return 0.5
            return (x - lo) / (hi - lo)

        final_items = []
        for fi, f_s, r_s in zip(fused_items, fusion_scores, rerank_scores):
            f_norm = _norm(f_s, f_min, f_max)
            r_norm = _norm(r_s, r_min, r_max)
            relevance = self.gamma * r_norm + (1 - self.gamma) * f_norm
            cost = 1.0 - relevance

            item = fi["item"]
            final_items.append({
                "text": item["text"],
                "table": item["table"],
                "metadata": item["metadata"],
                "modality": item["modality"],
                "score": cost,
            })

        # ------------------------------------------------------
        # 6ï¸âƒ£ æœ€ç»ˆæ’åº + top_k
        # ------------------------------------------------------
        final_items.sort(key=lambda x: x["score"])
        final_items = final_items[:top_k]

        # è¾“å‡ºæ ¼å¼ä¿æŒå’Œæ—§ç‰ˆä¸€è‡´
        return [
            {
                "text": it["text"],
                "table": it["table"],
                "score": round(float(it["score"]), 4),
                "metadata": it["metadata"],
            }
            for it in final_items
        ]


    # ------------------------------------------------------
    # ä¸Šä¸‹æ–‡æ‹¼æ¥æ¥å£
    # ------------------------------------------------------
    def retrieve_context(self, query: str, top_k: int = 5):
        hits = self.retrieve(query, top_k=top_k)
        return "\n---\n".join([h["text"] for h in hits if h["text"]])


# -------------------------
# è‡ªæµ‹
# -------------------------
if __name__ == "__main__":
    rag = RAGInterface()
    q = "AIAæ„å¤–é™©çš„èµ”ä»˜èŒƒå›´æ˜¯ä»€ä¹ˆï¼Ÿ"
    res = rag.retrieve(q, top_k=3)
    for r in res:
        print(">>> TEXT:", r["text"])
        print(">>> TABLE STRUCT:", r["table"])      # â† è§£å‹åçš„è¡¨æ ¼ JSON
        print(">>> META:", r["metadata"])
    # print(f"\nğŸ” Query: {q}")
    # for i, r in enumerate(res, 1):
    #     print(f"\n{i}. [score={r['score']}]")
    #     print(r["text"][:300], "...")
    #     print("metadata:", r["metadata"])
    # qvec_table = Embedder().embed_query_table(q)
    # hits = MilvusVectorStore().search_table(qvec_table, top_k=5)

    # for h in hits:
    #     ent = h.entity
    #     table_blob = ent.get("table_blob") or ""
    #     table_json = table = json.loads(zlib.decompress(base64.b64decode(table_blob)).decode())
    #     print("\nTABLEï¼š", table_json)
    #     print("\nTEXT:", ent.get("text")[:300], "...")
    #     print("METADATA:", ent.get("metadata"))
    #     print("SCORE:", h.score)

